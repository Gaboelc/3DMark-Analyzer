{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parsers.parser import ZipParser\n",
    "from parsers.monitoring_parser import separate_and_order_columns, validate_cpu_data, validate_gpu_data, monitoring_etl\n",
    "from parsers.results_parser import extract_results_data\n",
    "from parsers.arielle_parser import extract_arielle_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_3dmark_files(raw_directory):\n",
    "\n",
    "    for filename in os.listdir(raw_directory):\n",
    "        if filename.endswith(\".3dmark-result\"):\n",
    "            file_path = os.path.join(raw_directory, filename)\n",
    "            print(f\"\"\"Processing file: \n",
    "                  {filename}\n",
    "                  \"\"\")\n",
    "\n",
    "            parser = ZipParser(file_path)\n",
    "            temp_dir = parser.extract_to_temp()\n",
    "\n",
    "            monitoring_file = os.path.join(temp_dir, 'Monitoring.csv')\n",
    "            result_file = os.path.join(temp_dir, 'Result.xml')\n",
    "            arielle_file = os.path.join(temp_dir, 'Arielle.xml')\n",
    "            \n",
    "            if os.path.exists(monitoring_file):\n",
    "                output_file = os.path.join(temp_dir, 'Monitoring_cleaned.csv')\n",
    "                df_monitoring = monitoring_etl(monitoring_file, output_file, threshold=0.3)\n",
    "                \n",
    "                if df_monitoring is not None:\n",
    "                    df_gpu, df_cpu = separate_and_order_columns(df_monitoring)\n",
    "\n",
    "                    cpu_validation_results = validate_cpu_data(df_cpu)\n",
    "                    print(\"\\n CPU validation results:\")\n",
    "                    print(cpu_validation_results)\n",
    "                    \n",
    "                    gpu_validation_results = validate_gpu_data(df_gpu)\n",
    "                    print(\"\\n GPU validation results:\")\n",
    "                    print(gpu_validation_results)\n",
    "\n",
    "                    print(\"\\n CPU Dataframe:\")\n",
    "                    print(df_cpu)\n",
    "                    \n",
    "                    print(\"\\n GPU Dataframe:\")\n",
    "                    print(df_gpu)\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not process file {filename}.\")\n",
    "            else:\n",
    "                print(f\"\\n The file Monitoring.csv was not found in {filename}\")\n",
    "            \n",
    "            if os.path.exists(result_file):\n",
    "                df_results = extract_results_data(result_file) \n",
    "                \n",
    "                if df_results is not None:\n",
    "                    results_target = df_results[df_results.columns[df_results.columns.str.contains('ForPass')]].dropna(axis=1, how='all').dropna(how='all')\n",
    "                    \n",
    "                    results = df_results[df_results.columns[~df_results.columns.str.contains(\"ForPass\")]].dropna(axis=1, how='all').dropna(how='all')\n",
    "                    \n",
    "                    if 'benchmarkRunId' in results_target.columns:\n",
    "                        results_target = results_target.drop(columns=['benchmarkRunId'])\n",
    "                    if 'passIndex' in results_target.columns:\n",
    "                        results_target = results_target.drop(columns=['passIndex'])\n",
    "                        \n",
    "                    if 'benchmarkRunId' in results.columns:\n",
    "                        results = results.drop(columns=['benchmarkRunId'])\n",
    "                    if 'passIndex' in results.columns:\n",
    "                        results = results.drop(columns=['passIndex'])\n",
    "                        results.iloc[0] = results.iloc[0].combine_first(results.iloc[1])\n",
    "                        results = results.drop(index=1).reset_index(drop=True)\n",
    "                    \n",
    "                    print(\"\\n Results Dataframe:\")\n",
    "                    print(results)\n",
    "                    \n",
    "                    print(\"\\n Results_target Dataframe:\")\n",
    "                    print(results_target)\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not process file {filename}.\")\n",
    "            else:\n",
    "                print(f\"\\n The file Result.xml was not found in {filename}\")\n",
    "                \n",
    "            if os.path.exists(arielle_file): \n",
    "                \n",
    "                df_app_info, df_hardware_info, df_test_info, df_workload_sets = extract_arielle_data(arielle_file)\n",
    "                \n",
    "                if df_app_info is not None and not df_app_info.empty:\n",
    "                    print(\"\\n Application Information:\")\n",
    "                    print(df_app_info)\n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not extract application info from {arielle_file}.\")\n",
    "                \n",
    "                if df_hardware_info is not None and not df_hardware_info.empty:\n",
    "                    print(\"\\nHardware Information:\")\n",
    "                    print(df_hardware_info)\n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not extract hardware info from {arielle_file}.\")\n",
    "                    \n",
    "                if df_test_info is not None and not df_test_info.empty:\n",
    "                    print(\"\\nTest Info Information:\")\n",
    "                    print(df_test_info)\n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not extract hardware info from {arielle_file}.\")\n",
    "                \n",
    "                if df_workload_sets is not None and not df_workload_sets.empty:\n",
    "                    print(\"\\nWorkload Set Information:\")\n",
    "                    print(df_workload_sets)\n",
    "                else:\n",
    "                    print(f\"\\n Warning: Could not extract hardware info from {arielle_file}.\")\n",
    "                    \n",
    "            else:\n",
    "                print(f\"\\n The file Arielle.xml was not found in {filename}\")\n",
    "                \n",
    "            if zip(df_gpu, df_cpu, results_target, results, df_app_info, df_hardware_info, df_test_info, df_workload_sets) is not None:\n",
    "                print(f\"\\n File {filename} processed successfully.\")\n",
    "                return df_gpu, df_cpu, results_target, results, df_app_info, df_hardware_info, df_test_info, df_workload_sets\n",
    "            else:\n",
    "                print(f\"\\n Warning: Could not process file {filename}.\")\n",
    "            \n",
    "            parser.clean_up()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_directory = \"./data/raw/\"\n",
    "\n",
    "df_gpu, df_cpu, results_target, results, df_app_info, df_hardware_info, df_test_info, df_workload_sets = process_3dmark_files(raw_directory)\n",
    "#process_3dmark_files(raw_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hardware_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DMark-Analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
